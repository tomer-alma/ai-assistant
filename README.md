# AI Voice Assistant

A voice-powered AI assistant with Hebrew language support, built with OpenAI's APIs for speech-to-text (STT), language model (LLM), and text-to-speech (TTS).

## Features

- ğŸ¤ **Voice Input**: Real-time speech recognition with voice activity detection (VAD)
- ğŸ¤– **AI Conversations**: Natural conversations powered by GPT models
- ğŸ”Š **Voice Output**: Text-to-speech with natural-sounding voices
- ğŸ‡®ğŸ‡± **Hebrew Support**: Full bidirectional text support for Hebrew
- ğŸ¯ **Echo Cancellation**: Advanced echo prevention to avoid self-responses
- ğŸ‘‹ **Configurable Greetings**: Customizable opening and closing messages
- ğŸšª **Voice Exit**: Say goodbye to exit gracefully
- âš¡ **Optimized Latency**: ~3-8 second response time (15-20% faster than baseline)

## Quick Start

### Prerequisites

- Python 3.10+
- OpenAI API key
- WSL2 with PulseAudio (for Linux/WSL users) or native audio support
- **For Raspberry Pi**: See [RASPBERRY_PI_SETUP.md](RASPBERRY_PI_SETUP.md) for detailed Pi 5 installation guide

### Installation

1. Clone the repository:
```bash
cd ~/ai-assistant
```

2. Create a virtual environment and install dependencies:
```bash
make install
```

3. Set up your OpenAI API key:
```bash
# Create a .env file
echo "OPENAI_API_KEY=your_api_key_here" > .env
```

Get your API key from: https://platform.openai.com/api-keys

### Running

```bash
make dev-run
```

The assistant will:
1. Greet you with a welcome message
2. Show "âœ… Ready! You can speak now."
3. Listen for your voice input
4. Respond naturally in Hebrew

### Exiting

Say any of these words to exit:
- "×œ×”×ª×¨××•×ª" (goodbye)
- "×‘×™×™" (bye)
- "bye"
- "×ª×¤×¡×™×§" (stop)
- "×¡×™×•×" (end)
- "×¢×¦×•×¨" (stop)
- "×™×¦×™××”" (exit)

Or press `Ctrl+C` to interrupt.

## Configuration

All settings are in `src/config/default.yaml`. 

- See [CONFIGURATION.md](CONFIGURATION.md) for greeting/exit settings and echo tuning
- See [LATENCY_IMPROVEMENTS.md](LATENCY_IMPROVEMENTS.md) for performance optimization details

### Key Settings

```yaml
language:
  greeting: "×©×œ×•×! ×× ×™ ×›××Ÿ ×œ×¢×–×•×¨ ×œ×š. ×‘××” ××•×›×œ ×œ×¡×™×™×¢?"
  closing: "×œ×”×ª×¨××•×ª! ×”×™×” × ×¢×™× ×œ×“×‘×¨ ××™×ª×š."
  style_prompt: "×¢× ×” ×‘×¢×‘×¨×™×ª ×§×¦×¨ ×•×‘×¨×•×¨, ×¢×“ 4 ××©×¤×˜×™×."

models:
  stt: "gpt-4o-mini-transcribe"
  llm: "gpt-4o-mini"
  tts: "gpt-4o-mini-tts"
  tts_voice: "nova"

audio:
  vad_aggressiveness: 2  # 0-3: lower = less sensitive

timeouts:
  stt_finalize_ms: 600  # Silence duration before ending speech (lower = faster)
  post_greeting_settle_ms: 1000  # Echo prevention after greeting
  post_response_settle_ms: 300  # Echo prevention after each response (lower = faster)

debugging:
  show_latency: true  # Display performance metrics
```

## Troubleshooting

### ALSA Warnings

The ALSA warnings you see in WSL2 are normal and harmless:
```
ALSA lib confmisc.c:855:(parse_card) cannot find card '0'
```

Audio works through PulseAudio (`PULSE_SERVER=/mnt/wslg/PulseServer`), so you can safely ignore these messages.

### Echo Issues

If the assistant responds to itself:
- Wait for "ğŸ¤ Listening..." before speaking
- Lower your speaker volume
- Use headphones
- See [CONFIGURATION.md](CONFIGURATION.md) for advanced tuning

### First STT After Greeting

If the first speech recognition doesn't work well:
- Wait for both "âœ… Ready!" and "ğŸ¤ Listening..." messages
- Increase `post_greeting_settle_ms` in `default.yaml` to 1500-2000

### API Timeouts

If you get connection timeouts:
- Check your internet connection
- Verify your OpenAI API key is valid
- The app has 60s timeout and 2 retries configured

## Project Structure

```
ai-assistant/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py              # Main conversation loop
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ default.yaml     # Configuration file
â”‚   â”‚   â””â”€â”€ settings.py      # Settings models
â”‚   â”œâ”€â”€ audio/
â”‚   â”‚   â”œâ”€â”€ capture.py       # Audio input capture
â”‚   â”‚   â”œâ”€â”€ playback.py      # Audio output playback
â”‚   â”‚   â””â”€â”€ vad.py           # Voice activity detection
â”‚   â”œâ”€â”€ stt/
â”‚   â”‚   â””â”€â”€ openai_stt.py    # Speech-to-text
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ openai_llm.py    # Language model
â”‚   â””â”€â”€ tts/
â”‚       â””â”€â”€ openai_tts.py    # Text-to-speech
â”œâ”€â”€ Makefile                 # Build commands
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md               # This file
```

## Development

### Available Make Commands

- `make venv` - Create virtual environment
- `make install` - Install all dependencies
- `make dev-run` - Run the assistant (WSL2/Linux with PulseAudio)
- `make pi-run` - Run the assistant (Raspberry Pi / native audio)
- `make clean` - Remove virtual environment

## License

MIT

## Credits

Built with OpenAI APIs, PyAudio, and WebRTC VAD.

